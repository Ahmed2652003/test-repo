{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3bff8d4-5e39-469e-8d0d-c9c55a6e3786",
   "metadata": {},
   "source": [
    "# Introduction & problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af940c84-1c52-43e0-b720-cf5f6a4d7346",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27eb8d8-ca47-497f-8cb3-d5f4dc40b2e4",
   "metadata": {},
   "source": [
    "### Millions of people are using Twitter and expressing their emotions like happiness, sadness, angry, etc. The Sentiment analysis is also about detecting the emotions, opinion, assessment, attitudes, and took this into consideration as a way humans think. Sentiment analysis classifies the emotions into classes such as positive or negative. Nowadays, industries are interested to use textual data for semantic analysis to extract the view of people about their products and services. Sentiment analysis is very important for them to know the customer satisfaction level and they can improve their services accordingly. To work on the text data, they try to extract the data from social media platforms. There are a lot of social media sites like Google Plus, Facebook, and Twitter that allow expressing opinions, views, and emotions about certain topics and events. Microblogging site Twitter is expanding rapidly among all other online social media networking sites with about 200 million users. Twitter was founded in 2006 and currently, it is the most famous microblogging platform. In 2017 2 million users shared 8.3 million tweets in one hour. Twitter users use to post their thoughts, emotions, and messages on their profiles, called tweets. Words limit of a single tweet has 140 characters. Twitter sentiment analysis based on the NLP (natural language processing) field. For tweets text, we use NLP techniques like tokenizing the words, removing the stop words like I, me, my, our, your, is, was, etc. Natural language processing also plays a part to preprocess the data like cleaning the text and removing the special characters and punctuation marks. Sentimental analysis is very important because we can know the trends of peopleâ€™s emotions on specific topics with their tweets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab30b6-dd18-4ea6-bdbb-227dbf28073f",
   "metadata": {},
   "source": [
    "## Problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9a1e7-4e55-4ea1-972e-cda1b8e6f10d",
   "metadata": {},
   "source": [
    "### To devise a sentimental analyzer for overcoming the challenges to identify the twitter tweets text sentiments (positive, negative) by using naive bayes , support vector classifier and logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96cfeda-65d2-4c42-b947-4840ffdc8cba",
   "metadata": {},
   "source": [
    "## Labraries importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea21663-5af3-44d6-980b-6361ad82c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import string\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd5c9c-50bc-4fd4-bbe8-c3fd2f732c6b",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4cf5c-0d29-4e55-9678-8bd6ca06897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data set\n",
    "data = pd.read_csv(\"data set.csv\", encoding=\"ISO-8859-1\", engine=\"python\")\n",
    "data.columns = [\"Sentiment\", \"Time\", \"Date\", \"Query\", \"Username\", \"Tweet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1b9121",
   "metadata": {},
   "source": [
    "# Exploratory data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3a3aa0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b931bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of data\n",
    "print(\"lenght of data is :\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8023e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac95506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types of all features\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Null values\n",
    "data.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0843ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describtion for data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a51ba",
   "metadata": {},
   "source": [
    "Mohammed Saeed A5oya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15190e7c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
